# Next-Word-Prediction

Dataset used: Sherlock Dataset(https://www.gutenberg.org/files/1661/1661-0.txtc)

Word Embedding used: **Glove.6b.100d.txt** by stanford(https://nlp.stanford.edu/projects/glove/)

**MODEL Spec's**
* input: 10 words
* output: 1 word
* Used Self Attention Layer for better results
* Accuracy: 70% (which could be further improved by more training)
* Link to the trained Model(https://drive.google.com/file/d/1p_8AAZUnOn7ULQddTS7Hg1IZ7Lv_9uDU/view?usp=sharing)
**Model Architecture**
![**Architecture**](https://github.com/yash88600/Next-Word-Prediction/blob/master/Model%20Summary.JPG)

